{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2(1111385).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwGyA3RVUCeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the pandas library to read our dataset\n",
        "import pandas as pd\n",
        "#To split the data into training and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#To manipulate data\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjKWhr7yUGik",
        "colab_type": "code",
        "outputId": "caaaa542-1d10-4360-93b7-8e82ff1bd557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# import data from the link\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv', sep='\\t')\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUsGtXA8Vb6r",
        "colab_type": "code",
        "outputId": "f9ade1ad-45bb-4d1d-a110-dc5a12ef41dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "#libraries used for data preprocessing\n",
        "import nltk\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFjSbffFUMnA",
        "colab_type": "code",
        "outputId": "d40dff37-3a9a-4ad1-a34c-5c991ed63dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#splitting each review into documents\n",
        "documents = []\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "  tmpWords = word_tokenize(data['Phrase'][i])\n",
        "  documents.append((tmpWords, data['Sentiment'][i]))\n",
        "\n",
        "print(documents[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['A', 'series', 'of', 'escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose'], 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLy8t7tRVrk7",
        "colab_type": "code",
        "outputId": "ba9727f1-03b4-49ca-c58b-0dcc339aeeea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "\n",
        "#parameters to adjust to see the impact on outcome\n",
        "remove_stopwords = True\n",
        "useStemming = True\n",
        "useLemma = False\n",
        "removePuncs = True\n",
        "\n",
        "for l in range(len(documents)):\n",
        "  label = documents[l][1]\n",
        "  tmpReview = []\n",
        "  for w in documents[l][0]:\n",
        "    newWord = w\n",
        "    if remove_stopwords and (w in stopwords_en):\n",
        "      continue\n",
        "    if removePuncs and (w in punctuations):\n",
        "      continue\n",
        "    if useStemming:\n",
        "      \n",
        "      newWord = lancaster.stem(newWord)\n",
        "    if useLemma:\n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord)\n",
        "    tmpReview.append(newWord)\n",
        "  documents[l] = (' '.join(tmpReview), label)\n",
        "print(documents[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('a sery escapad demonst ad good goos', 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs5ATc3rWNMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = pd.DataFrame(documents, columns=['Phrase', 'Sentiment'])\n",
        "x_train, x_test, y_train, y_test = train_test_split(all_data['Phrase'], all_data['Sentiment'], train_size = 0.7, shuffle = True, random_state = 2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOHRP0n3WSCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vectorize the data \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words = 'english', ngram_range= (1,1), max_features=1500)\n",
        "X = vectorizer.fit_transform(all_data['Phrase'])\n",
        "x_train = vectorizer.transform(x_train)\n",
        "x_test = vectorizer.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7DbD776WYbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_np = x_train.toarray()\n",
        "y_train_np = to_categorical(y_train)\n",
        "x_test_np = x_test.toarray()\n",
        "y_test_np = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7PXtdgOYBa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.expand_dims(x_train_np, axis=2)\n",
        "x_test = np.expand_dims(x_test_np, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq7w0aPuYcXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "4995f010-1052-417b-9bbf-4c3ec7f85ea8"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "#model creation\n",
        "model = Sequential()\n",
        "#defing the layers\n",
        "model.add(Conv1D(filters = 128, kernel_size=1, activation='relu', input_shape=(x_train_np.shape[1],1)))\n",
        "model.add(Conv1D(filters = 128, kernel_size=1, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Conv1D(filters = 128, kernel_size=1, activation='relu'))\n",
        "model.add(Conv1D(filters = 128, kernel_size=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size =2))\n",
        "model.add(Flatten())\n",
        "keras.layers.Dropout(0.1, noise_shape=None, seed=None)\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx9smFmljarP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "8133e3dc-0e3c-4e04-e013-9adef6d02155"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 1500, 128)         256       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1500, 128)         16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1500, 100)         12900     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1500, 128)         12928     \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 1500, 128)         16512     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 750, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 96000)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               9600100   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 9,659,713\n",
            "Trainable params: 9,659,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJfSdXRhZUj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "18b2b592-05cc-464f-d265-5e64fb140065"
      },
      "source": [
        "#model compilation and optimizer used is adamax\n",
        "model.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKv1KCfZZbQF",
        "colab_type": "code",
        "outputId": "64228e64-6d1f-47a6-d5f2-ede350a8f569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "#Trainig the model\n",
        "model.fit(x_train, y_train_np, validation_data=(x_test, y_test_np), epochs = 10, batch_size = 128)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 109242 samples, validate on 46818 samples\n",
            "Epoch 1/10\n",
            "109242/109242 [==============================] - 112s 1ms/step - loss: 1.0899 - acc: 0.5630 - val_loss: 1.0663 - val_acc: 0.5791\n",
            "Epoch 2/10\n",
            "109242/109242 [==============================] - 112s 1ms/step - loss: 1.0425 - acc: 0.5864 - val_loss: 1.0594 - val_acc: 0.5840\n",
            "Epoch 3/10\n",
            "109242/109242 [==============================] - 113s 1ms/step - loss: 0.9892 - acc: 0.6136 - val_loss: 1.0187 - val_acc: 0.6011\n",
            "Epoch 4/10\n",
            "109242/109242 [==============================] - 113s 1ms/step - loss: 0.9306 - acc: 0.6393 - val_loss: 1.0116 - val_acc: 0.6079\n",
            "Epoch 5/10\n",
            "109242/109242 [==============================] - 112s 1ms/step - loss: 0.8824 - acc: 0.6584 - val_loss: 1.0131 - val_acc: 0.6131\n",
            "Epoch 6/10\n",
            "109242/109242 [==============================] - 112s 1ms/step - loss: 0.8452 - acc: 0.6738 - val_loss: 1.0060 - val_acc: 0.6144\n",
            "Epoch 7/10\n",
            "109242/109242 [==============================] - 112s 1ms/step - loss: 0.8153 - acc: 0.6853 - val_loss: 1.0182 - val_acc: 0.6122\n",
            "Epoch 8/10\n",
            "109242/109242 [==============================] - 112s 1ms/step - loss: 0.7914 - acc: 0.6947 - val_loss: 1.0502 - val_acc: 0.6137\n",
            "Epoch 9/10\n",
            "109242/109242 [==============================] - 112s 1ms/step - loss: 0.7695 - acc: 0.7033 - val_loss: 1.0499 - val_acc: 0.6151\n",
            "Epoch 10/10\n",
            "109242/109242 [==============================] - 112s 1ms/step - loss: 0.7514 - acc: 0.7092 - val_loss: 1.0900 - val_acc: 0.6135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc71e6cae48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d99AkxxOj_vl",
        "colab_type": "code",
        "outputId": "08a394d7-0715-4561-9397-b20eed8ec258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "\n",
        "#checking the metrics\n",
        "train_accu = model.evaluate(x_train, y_train_np, verbose=0) \n",
        "test_accu = model.evaluate(x_test, y_test_np, verbose=0)\n",
        "\n",
        "print(\"train accuracy: %.2f%%\" % (train_accu[1]*100))\n",
        "print(\"test_accuracy: %.2f%%\" % (test_accu[1]*100))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy: 73.81%\n",
            "test_accuracy: 61.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Epw-hrP3peT",
        "colab_type": "code",
        "outputId": "1e21a5da-c8ca-4977-b5ec-4d5fff2c64ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "y_pred = model.predict_classes(x_test, batch_size=128, verbose=0)\n",
        "y_pred1=np.argmax(y_test_np, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_pred1, y_pred)\n",
        "precision = precision_score(y_pred1, y_pred, average='weighted')\n",
        "f1 = f1_score(y_pred1, y_pred, average='weighted')\n",
        "recall = recall_score(y_pred1, y_pred, average='weighted')\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('Precision: %f' % precision)\n",
        "print('Recall: %f' % recall)\n",
        "print('F1 score: %f' % f1)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.613546\n",
            "Precision: 0.591608\n",
            "Recall: 0.613546\n",
            "F1 score: 0.591169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cj1LQrPkMcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('1111385_1dconv_reg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoCasMlb86Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('1111385_1dconv_reg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}